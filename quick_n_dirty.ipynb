{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass\n",
      "YrSold\n",
      "SaleType\n",
      "Condition1\n",
      "Condition2\n",
      "Neighborhood\n",
      "Street\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train = pd.read_csv(\"train.csv\",index_col=\"Id\")\n",
    "test = pd.read_csv(\"test.csv\",index_col=\"Id\")\n",
    "\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_columns', 999)\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "def mape(actual, pred):\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100.0\n",
    "\n",
    "def banding(series,n_bands):\n",
    "    \"\"\"\n",
    "    Takes in a df column of type float/int and maps this into 'bands' of values between min and max values\n",
    "    For example band(df[\"OverallQual\"],3) splits into 3 bands evenly spaced between max and min.\n",
    "    Useful for features like Year Built\n",
    "    \"\"\"\n",
    "    bands = np.linspace(series.min(),series.max(),n_bands)\n",
    "    band_dic = dict((val,int(key)) for (key,val) in zip(np.arange(1,len(bands)+1,1),bands))\n",
    "    def allocate_band(y):\n",
    "        closest = min(bands, key=lambda x:abs(x-y))\n",
    "        return band_dic[closest]\n",
    "    return series.apply(lambda x: int(allocate_band(x)))\n",
    "\n",
    "def scaling(df):\n",
    "    df = df.fillna(value=0)\n",
    "    ###### TRANSFORMS\n",
    "   # df[\"OverallQual\"] = banding(df[\"OverallQual\"],2) \n",
    "   # df[\"OverallCond\"] = banding(df[\"OverallCond\"],2) \n",
    "   # df[\"YearBuilt\"] = banding(df[\"YearBuilt\"],3)\n",
    "   # df[\"TotRmsAbvGrd\"] = banding(df[\"TotRmsAbvGrd\"],3)\n",
    "\n",
    "    df[\"OverallQual\"] = MinMaxScaler().fit_transform(df[\"OverallQual\"].apply(float).reshape(-1,1))\n",
    "    df[\"OverallCond\"] = MinMaxScaler().fit_transform(df[\"OverallCond\"].apply(float).reshape(-1,1))\n",
    "    df[\"YearBuilt\"] = MinMaxScaler().fit_transform(df[\"YearBuilt\"].apply(float).reshape(-1,1))\n",
    "    df[\"TotRmsAbvGrd\"] = MinMaxScaler().fit_transform(df[\"TotRmsAbvGrd\"].apply(float).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    ## Float > Log > Normalise\n",
    "\n",
    "    df[\"LotArea\"] = MinMaxScaler().fit_transform(np.log(df[\"LotArea\"]).reshape(-1,1))\n",
    "\n",
    "    #print(train.loc[train[\"TotalBsmtSF\"] != 0, [\"TotalBsmtSF\"]])\n",
    "    #print(train[[\"TotalBsmtSF\"]])\n",
    "\n",
    "    # Rescale for only the non-zero values\n",
    "    df.loc[df[\"TotalBsmtSF\"] != 0, [\"TotalBsmtSF\"]] = MinMaxScaler().fit_transform(\n",
    "        np.log(df.loc[df[\"TotalBsmtSF\"] != 0, [\"TotalBsmtSF\"]]))#.reshape(-1,1))\n",
    "\n",
    "    # This is actually fairly Gaussian w/o log transform\n",
    "    #train[train[\"GarageArea\"] == 0] = 1\n",
    "    df[\"GarageArea\"] = MinMaxScaler().fit_transform((df[\"GarageArea\"].apply(float)).reshape(-1,1))\n",
    "    \n",
    "    df[\"GrLivArea\"] = MinMaxScaler().fit_transform((df[\"GrLivArea\"].apply(float)).reshape(-1,1))\n",
    "\n",
    "    # Maybe reonsider this scaling...might be shitty > Check histogram\n",
    "    df.loc[df[\"PoolArea\"] == 0, [\"PoolArea\"]] = 1\n",
    "    df[\"PoolArea\"] = MinMaxScaler().fit_transform((df[\"PoolArea\"].apply(float)).reshape(-1,1))\n",
    "\n",
    "    df[\"1stFlrSF\"] = MinMaxScaler().fit_transform((df[\"1stFlrSF\"].apply(float)).reshape(-1,1))\n",
    "\n",
    "    df.loc[df[\"2ndFlrSF\"] == 0, [\"2ndFlrSF\"]] = 1\n",
    "    df[\"2ndFlrSF\"] = MinMaxScaler().fit_transform((df[\"2ndFlrSF\"].apply(float)).reshape(-1,1))\n",
    "\n",
    "    # Now do some one hot encoding on all categoricals\n",
    "    df[\"Condition2\"] = df[\"Condition2\"].apply(str)+\"c2\" # fix join bug with encoding\n",
    "#    df[\"Utilities\"] = df[\"Utilities\"].fillna(\"AllPub\")\n",
    "    for cat in categoricals:\n",
    "        print(cat)\n",
    "        dummies = pd.get_dummies(df[cat])\n",
    "        df = df.drop(cat,axis=1)\n",
    "        df = df.join(dummies)\n",
    "    return df\n",
    "\n",
    "\n",
    "predictors = [\"LotArea\",\"MSSubClass\",\"OverallQual\",\"OverallCond\",\"YearBuilt\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\n",
    "              \"TotRmsAbvGrd\",\"GarageArea\",\"PoolArea\",\"YrSold\",\"SaleCondition\",\"SaleType\",\"Condition1\",\"Condition2\",\n",
    "              \"Neighborhood\",\"Street\",\"GrLivArea\"]\n",
    "\n",
    "categoricals = [\"MSSubClass\",\"YrSold\",\"SaleType\",\"Condition1\",\"Condition2\",\n",
    "              \"Neighborhood\",\"Street\",\"SaleCondition\"]\n",
    "\n",
    "target = train[\"SalePrice\"]\n",
    "train = train.drop(\"SalePrice\",axis=1)\n",
    "\n",
    "train = train[predictors]\n",
    "test = test[predictors]\n",
    "\n",
    "dd = pd.concat([train,test])\n",
    "dd = scaling(dd)\n",
    "\n",
    "train = dd[:len(train)]\n",
    "test = dd[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172407354487\n",
      "0.171929755477\n",
      "0.171594215489\n",
      "0.05 0.1492163228\n",
      "0.1 0.148650980244\n",
      "0.3 0.14710080085\n",
      "1 0.144798017187\n",
      "3 0.143980380788\n",
      "5 0.144949173657\n",
      "10 0.149382645815\n",
      "15 0.154782867603\n",
      "30 0.171232675249\n",
      "50 0.1901697541\n",
      "75 0.209064268614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn import cross_validation\n",
    "\n",
    "alg = RandomForestRegressor(n_estimators = 500, oob_score = False, n_jobs = -1,random_state =1,\n",
    "                            max_features = 10, min_samples_leaf = 2)\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def rmse_cv(model):\n",
    "   # print(cross_val_score(model, train, np.log(target), scoring=\"mean_squared_error\", cv = 5))\n",
    "    rmse= np.sqrt(-cross_val_score(model, train, np.log(target), scoring=\"mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "for x in [100,500,1000]:\n",
    "    print(rmse_cv(RandomForestRegressor(n_estimators = x, n_jobs = -1,random_state =1,\n",
    "                            max_features = 4, min_samples_leaf = 2)).mean())\n",
    "\n",
    "for a in [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]:\n",
    "    print(a, rmse_cv(Ridge(alpha = a)).mean())\n",
    "\n",
    "#print(test[[\"SalePrice\"]])\n",
    "#test[[\"SalePrice\"]].to_csv(\"submit.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-745aa3a2d734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
