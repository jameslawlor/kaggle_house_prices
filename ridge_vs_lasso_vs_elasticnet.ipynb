{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook produces a cross validation comparison of the linear models Ridge, Lasso and ElasticNet with $\\alpha$ tuning. At the time of publication this script performs in the top ~15% of submissions. Using a RMSE for evaluation it is found that ElasticNet appears slightly better than the Lasso and Ridge models. Some basic preprocessing and feature creation is also included but it should be emphasised that the median imputation used on missing values is very crude. For example, Area features with missing values may be this way because the property does not have that feature (e.g. a pool) so it would make more sense to set this to zero. Feature creation is done by taking the square root of all numerical area features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.read_csv(\"train.csv\",index_col=\"Id\")\n",
    "test = pd.read_csv(\"test.csv\",index_col=\"Id\")\n",
    "\n",
    "def print_full(x):\n",
    "    \"\"\"\n",
    "    Full printing of dataframes for error checking\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_columns', 999)\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "def clean(df):\n",
    "    \"\"\"\n",
    "    Cleans NaNs and creates new features\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of new features to be created: (new_feature, original_feature, transform_function)\n",
    "    transform = [(\"sqLotArea\",\"LotArea\",np.sqrt),\n",
    "                 (\"sqGrLivArea\",\"GrLivArea\",np.sqrt),\n",
    "                 (\"sqBsmtFinSF1\",\"BsmtFinSF1\",np.sqrt),\n",
    "                 (\"sqBsmtFinSF2\",\"BsmtFinSF2\",np.sqrt),\n",
    "                 (\"sqBsmtUnfSF\",\"BsmtUnfSF\",np.sqrt),\n",
    "                 (\"sqTotalBsmtSF\",\"TotalBsmtSF\",np.sqrt),\n",
    "                 (\"sq1stFlrSF\",\"1stFlrSF\",np.sqrt),\n",
    "                 (\"sq2ndFlrSF\",\"2ndFlrSF\",np.sqrt),\n",
    "                 (\"sqLotFrontage\",\"LotFrontage\",np.sqrt),\n",
    "                 (\"sqMasVnrArea\",\"MasVnrArea\",np.sqrt),\n",
    "                 (\"sqPoolArea\",\"PoolArea\",np.sqrt),\n",
    "                 (\"sqGarageArea\",\"GarageArea\",np.sqrt),\n",
    "                 (\"sqWoodDeckSF\",\"WoodDeckSF\",np.sqrt),\n",
    "                 (\"sqOpenPorchSF\",\"OpenPorchSF\",np.sqrt),\n",
    "                 (\"sqEnclosedPorch\",\"EnclosedPorch\",np.sqrt),\n",
    "                ]\n",
    " \n",
    "    transform += [(\"lnLotArea\",\"LotArea\",lambda x: np.log(x+1)),\n",
    "                 (\"lnGrLivArea\",\"GrLivArea\",lambda x: np.log(x+1)),\n",
    "                 (\"lnBsmtFinSF1\",\"BsmtFinSF1\",lambda x: np.log(x+1)),\n",
    "                 (\"lnBsmtFinSF2\",\"BsmtFinSF2\",lambda x: np.log(x+1)),\n",
    "                 (\"lnBsmtUnfSF\",\"BsmtUnfSF\",lambda x: np.log(x+1)),\n",
    "                 (\"lnTotalBsmtSF\",\"TotalBsmtSF\",lambda x: np.log(x+1)),\n",
    "                 (\"ln1stFlrSF\",\"1stFlrSF\",lambda x: np.log(x+1)),\n",
    "                 (\"ln2ndFlrSF\",\"2ndFlrSF\",lambda x: np.log(x+1)),\n",
    "                 (\"lnLotFrontage\",\"LotFrontage\",lambda x: np.log(x+1)),\n",
    "                 (\"lnMasVnrArea\",\"MasVnrArea\",lambda x: np.log(x+1)),\n",
    "                 (\"lnPoolArea\",\"PoolArea\",lambda x: np.log(x+1)),\n",
    "                 (\"lnGarageArea\",\"GarageArea\",lambda x: np.log(x+1)),\n",
    "                 (\"lnWoodDeckSF\",\"WoodDeckSF\",lambda x: np.log(x+1)),\n",
    "                 (\"lnOpenPorchSF\",\"OpenPorchSF\",lambda x: np.log(x+1)),\n",
    "                 (\"lnEnclosedPorch\",\"EnclosedPorch\",lambda x: np.log(x+1)),\n",
    "                ]\n",
    "\n",
    "    # Find categorical and numerical features\n",
    "    categoricals = df.select_dtypes(include=[\"object\"]).columns.values\n",
    "    numericals = [feat for feat in df.select_dtypes(include=[\"int\",\"float\"]).columns.values]\n",
    "\n",
    "    cat_nan_nonestr = [\"PoolQC\",\"Fence\",\"MiscFeature\",\"FireplaceQu\",\"GarageType\",\n",
    "                    \"GarageFinish\",\"GarageQual\",\"GarageCond\",\"BsmtQual\",\"BsmtCond\",\n",
    "                    \"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"MasVnrType\",\"Alley\"]\n",
    "    \n",
    "    num_nan_zero = [\"LotFrontage\",\"MasVnrArea\",\"GarageYrBlt\"]\n",
    "    \n",
    "    # Transform to create new features, scale using MinMaxScaler\n",
    "    for (new_feature,original_feature,f) in transform: \n",
    "        df[new_feature] = df[original_feature].fillna(df[original_feature].median(), inplace = False)\n",
    "        df[new_feature] = MinMaxScaler().fit_transform(f(df[new_feature].apply(float)).reshape(-1,1))\n",
    "    # Scale and remove NaNs for numerical features by imputing median value\n",
    "    for feature in numericals: \n",
    "        if feature in num_nan_zero:\n",
    "            df[feature].fillna(0, inplace = True)\n",
    "        else:\n",
    "            df[feature].fillna(df[feature].median(), inplace = True)\n",
    "        df[feature] = MinMaxScaler().fit_transform(df[feature].apply(float).reshape(-1,1))\n",
    "    # Impute NaNs for categorical features\n",
    "    for feature in categoricals: \n",
    "        if feature in cat_nan_nonestr:\n",
    "            df[feature].fillna(\"None\", inplace = True)\n",
    "        else:\n",
    "            df[feature].fillna(df[feature].value_counts().idxmax(), inplace = True)\n",
    "            \n",
    "    # Perform one hot encoding on the categorical features\n",
    "    for cat in categoricals:\n",
    "        dummies = pd.get_dummies(df[cat])\n",
    "        dummies.columns = [col_name + cat for col_name in dummies.columns.values]            \n",
    "        df = df.drop(cat,axis=1)\n",
    "        df = df.join(dummies)\n",
    "    \n",
    "    return df\n",
    "\n",
    "target = train[\"SalePrice\"] # Note that we will take the Log of this when fitting - check the histogram of this feature\n",
    "train = train.drop(\"SalePrice\",axis=1)\n",
    "\n",
    "dd = clean(pd.concat([train,test]))\n",
    "\n",
    "train = dd[:len(train)]\n",
    "test = dd[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Lasso Regression=====\n",
      "0.0001 0.129152055831\n",
      "0.0002 0.126566053252\n",
      "0.0003 0.126499332894\n",
      "0.0004 0.127162438599\n",
      "0.0005 0.127937700184\n",
      "0.0006 0.128494979297\n",
      "0.0007 0.129068253425\n",
      "0.0008 0.129874977002\n",
      "0.0009 0.130792734432\n",
      "=====Ridge Regression=====\n",
      "1 0.131146319871\n",
      "2 0.130913804663\n",
      "3 0.130994640069\n",
      "4 0.131131428147\n",
      "5 0.131274562701\n",
      "6 0.131412255129\n",
      "7 0.131542155299\n",
      "8 0.131664527782\n",
      "9 0.131780299091\n",
      "=====ElasticNet=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best alpha value: 0.000393\n",
      " Best l1_ratio value: 0.500000\n",
      "0.125544566389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LassoLarsCV, ElasticNetCV\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def rmse_cv(model): # Cross val using the competition scoring metric\n",
    "    return(np.sqrt(-cross_val_score(model, train, np.log(target), scoring=\"mean_squared_error\", cv = 10)))\n",
    "\n",
    "print(\"=====Lasso Regression=====\")\n",
    "for a in np.arange(1.0e-4,1.0e-3,1.0e-4):\n",
    "    print(a, rmse_cv(Lasso(alpha = a,max_iter=100000)).mean())\n",
    "    \n",
    "print(\"=====Ridge Regression=====\")\n",
    "for a in np.arange(1,10,1):\n",
    "    print(a, rmse_cv(Ridge(alpha = a)).mean())\n",
    "    \n",
    "print(\"=====ElasticNet=====\")\n",
    "\n",
    "encv = ElasticNetCV(l1_ratio=[0.25, 0.5, 0.75, 0.9],\n",
    "             eps=0.0000001,\n",
    "             n_alphas=100,\n",
    "             max_iter=100000,\n",
    "             cv=10,\n",
    "             verbose=False,\n",
    "             precompute=True,\n",
    "             random_state=1, n_jobs=-1).fit(train, np.log(target))\n",
    "print(\" Best alpha value: %f\" % encv.alpha_ )\n",
    "print(\" Best l1_ratio value: %f\" % encv.l1_ratio_ )\n",
    "print(rmse_cv(ElasticNet(alpha = encv.alpha_,\n",
    "                            l1_ratio=encv.l1_ratio_,\n",
    "                            max_iter=100000,\n",
    "                            random_state=1).fit(train, np.log(target))\n",
    "                ).mean())\n",
    "\n",
    "best_model = ElasticNet(alpha = encv.alpha_,\n",
    "                            l1_ratio=encv.l1_ratio_,\n",
    "                            max_iter=100000,\n",
    "                            random_state=1).fit(train, np.log(target))\n",
    "\n",
    "# Output to CSV\n",
    "test[\"SalePrice\"] = np.exp(best_model.predict(test))\n",
    "test[[\"SalePrice\"]].to_csv(\"submit.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
