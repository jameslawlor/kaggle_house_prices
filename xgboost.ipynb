{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.read_csv(\"train.csv\",index_col=\"Id\")\n",
    "test = pd.read_csv(\"test.csv\",index_col=\"Id\")\n",
    "\n",
    "def print_full(x):\n",
    "    \"\"\"\n",
    "    Full printing of dataframes for error checking\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_columns', 999)\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_rows')\n",
    "\n",
    "def clean(df):\n",
    "    \"\"\"\n",
    "    Cleans NaNs and creates new features\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of new features to be created: (new_feature, original_feature, transform_function)\n",
    "    transform = [(\"sqLotArea\",\"LotArea\",np.sqrt),\n",
    "                 (\"sqGrLivArea\",\"GrLivArea\",np.sqrt),\n",
    "                 (\"sqBsmtFinSF1\",\"BsmtFinSF1\",np.sqrt),\n",
    "                 (\"sqBsmtFinSF2\",\"BsmtFinSF2\",np.sqrt),\n",
    "                 (\"sqBsmtUnfSF\",\"BsmtUnfSF\",np.sqrt),\n",
    "                 (\"sqTotalBsmtSF\",\"TotalBsmtSF\",np.sqrt),\n",
    "                 (\"sq1stFlrSF\",\"1stFlrSF\",np.sqrt),\n",
    "                 (\"sq2ndFlrSF\",\"2ndFlrSF\",np.sqrt),\n",
    "                 (\"sqLotFrontage\",\"LotFrontage\",np.sqrt),\n",
    "                 (\"sqMasVnrArea\",\"MasVnrArea\",np.sqrt),\n",
    "                 (\"sqPoolArea\",\"PoolArea\",np.sqrt),\n",
    "                 (\"sqGarageArea\",\"GarageArea\",np.sqrt),\n",
    "                 (\"sqWoodDeckSF\",\"WoodDeckSF\",np.sqrt),\n",
    "                 (\"sqOpenPorchSF\",\"OpenPorchSF\",np.sqrt),\n",
    "                 (\"sqEnclosedPorch\",\"EnclosedPorch\",np.sqrt),\n",
    "#                  (\"expLotArea\",\"LotArea\",np.exp),\n",
    "#                  (\"expGrLivArea\",\"GrLivArea\",np.exp),\n",
    "#                  (\"expBsmtFinSF1\",\"BsmtFinSF1\",np.exp),\n",
    "#                  (\"expBsmtFinSF2\",\"BsmtFinSF2\",np.exp),\n",
    "#                  (\"expBsmtUnfSF\",\"BsmtUnfSF\",np.exp),\n",
    "#                  (\"expTotalBsmtSF\",\"TotalBsmtSF\",np.exp),\n",
    "#                  (\"exp1stFlrSF\",\"1stFlrSF\",np.exp),\n",
    "#                  (\"exp2ndFlrSF\",\"2ndFlrSF\",np.exp),\n",
    "#                  (\"expLotFrontage\",\"LotFrontage\",np.exp),\n",
    "#                  (\"expMasVnrArea\",\"MasVnrArea\",np.exp),\n",
    "#                  (\"expPoolArea\",\"PoolArea\",np.exp),\n",
    "#                  (\"expGarageArea\",\"GarageArea\",np.exp),\n",
    "#                  (\"expWoodDeckSF\",\"WoodDeckSF\",np.exp),\n",
    "#                  (\"expOpenPorchSF\",\"OpenPorchSF\",np.exp),\n",
    "#                  (\"expEnclosedPorch\",\"EnclosedPorch\",np.exp),\n",
    "                 (\"lnLotArea\",\"LotArea\",np.log1p),\n",
    "                 (\"lnGrLivArea\",\"GrLivArea\",np.log1p),\n",
    "                 (\"lnBsmtFinSF1\",\"BsmtFinSF1\",np.log1p),\n",
    "                 (\"lnBsmtFinSF2\",\"BsmtFinSF2\",np.log1p),\n",
    "                 (\"lnBsmtUnfSF\",\"BsmtUnfSF\",np.log1p),\n",
    "                 (\"lnTotalBsmtSF\",\"TotalBsmtSF\",np.log1p),\n",
    "                 (\"ln1stFlrSF\",\"1stFlrSF\",np.log1p),\n",
    "                 (\"ln2ndFlrSF\",\"2ndFlrSF\",np.log1p),\n",
    "                 (\"lnLotFrontage\",\"LotFrontage\",np.log1p),\n",
    "                 (\"lnMasVnrArea\",\"MasVnrArea\",np.log1p),\n",
    "                 (\"lnPoolArea\",\"PoolArea\",np.log1p),\n",
    "                 (\"lnGarageArea\",\"GarageArea\",np.log1p),\n",
    "                 (\"lnWoodDeckSF\",\"WoodDeckSF\",np.log1p),\n",
    "                 (\"lnOpenPorchSF\",\"OpenPorchSF\",np.log1p),\n",
    "                 (\"lnEnclosedPorch\",\"EnclosedPorch\",np.log1p),\n",
    "                ]\n",
    "    \n",
    "    # Find categorical and numerical features\n",
    "    categoricals = train.select_dtypes(include=[\"object\"]).columns.values\n",
    "    numericals = [feat for feat in train.select_dtypes(include=[\"int\",\"float\"]).columns.values]\n",
    "    \n",
    "    # Remove NaNs... bear in mind this is a rough script. I recommend a more intelligent way of doing this,\n",
    "    # for example a feature like LotFrontage may be NaN because the property has no Lot Frontage, so it makes\n",
    "    # more sense to set this to zero instead of imputing the median value as shown below.\n",
    "    \n",
    "    # Transform to create new features, scale using MinMaxScaler\n",
    "    for (new_feature,original_feature,f) in transform: \n",
    "        df[new_feature] = df[original_feature].fillna(df[original_feature].median(), inplace = False)\n",
    "        df[new_feature] = MinMaxScaler().fit_transform(f(df[new_feature].apply(float)).reshape(-1,1))\n",
    "    # Scale and remove NaNs for numerical features by imputing median value\n",
    "    for feature in numericals: \n",
    "        df[feature].fillna(df[feature].median(), inplace = True)\n",
    "        df[feature] = MinMaxScaler().fit_transform(df[feature].apply(float).reshape(-1,1))\n",
    "    # Impute NaNs for categorical features\n",
    "    for feature in categoricals: \n",
    "        df[feature].fillna(df[feature].value_counts().idxmax(), inplace = True)\n",
    "    # Perform one hot encoding on the categorical features\n",
    "    for cat in categoricals:\n",
    "        dummies = pd.get_dummies(df[cat])\n",
    "        dummies.columns = [col_name + cat for col_name in dummies.columns.values]            \n",
    "        df = df.drop(cat,axis=1)\n",
    "        df = df.join(dummies)\n",
    "    return df\n",
    "\n",
    "target = train[\"SalePrice\"] # Note that we will take the Log of this when fitting - check the histogram of this feature\n",
    "train = train.drop(\"SalePrice\",axis=1)\n",
    "\n",
    "dd = clean(pd.concat([train,test]))\n",
    "\n",
    "train = dd[:len(train)]\n",
    "test = dd[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def rmse_cv(model,X,y): # Cross val using the competition scoring metric\n",
    "    return(np.sqrt(-cross_val_score(model, X, np.log(y), scoring=\"mean_squared_error\", cv = 5)))\n",
    "\n",
    "# def rmse(actual,pred):\n",
    "#     return(np.sqrt( ( (actual-pred)**2).mean()))\n",
    "\n",
    "\n",
    "# dtrain = xgb.DMatrix(train)\n",
    "# dtarget = xgb.DMatrix(target)\n",
    "# dtest =  xgb.DMatrix(test)\n",
    "\n",
    "cv_params = {'learning_rate':[0.01,0.07,0.1],} #, 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'max_depth': 3,\n",
    "              'n_estimators': 6000,\n",
    "              'seed':0,\n",
    "              \"subsample\": 0.8,\n",
    "              \"colsample_bytree\": 0.8,\n",
    "              \"colsample_bylevel\": 0.8, \n",
    "             'objective': 'reg:linear'}\n",
    "\n",
    "# optimized_xgb = GridSearchCV(xgb.XGBRegressor(**ind_params), \n",
    "#                             cv_params, \n",
    "#                             scoring = 'mean_squared_error', cv = 3, n_jobs = -1) \n",
    "\n",
    "# optimized_xgb.fit(train, target)\n",
    "# print(optimized_xgb.best_params_)\n",
    "# stop\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "                 gamma=0.030,                 \n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=3,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=10000,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.8,\n",
    "                 colsample_bytree= 0.8,\n",
    "                 colsample_bylevel= 0.8,\n",
    "                )\n",
    "\n",
    "model.fit(train,np.log(target))\n",
    "preds = np.exp(model.predict(test))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model2 = ElasticNet(alpha=0.0009).fit(train,np.log(target))\n",
    "model2.fit(train,np.log(target))\n",
    "preds2 = np.exp(model2.predict(test))\n",
    "\n",
    "\n",
    "results = (preds + preds2) / 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {\"n_jobs\": -1,\n",
    "         \"n_estimators\": 1000,\n",
    "         \"max_features\": \"auto\",\n",
    "          \"min_samples_leaf\": 5,\n",
    "          \"oob_score\": True,\n",
    "          \"random_state\" : 42\n",
    "         }\n",
    "\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "\n",
    "rf_model.fit(train,np.log(target))\n",
    "pred_rf = np.exp(rf_model.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/lib/python3.5/site-packages/keras/models.py:603: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1314 samples, validate on 146 samples\n",
      "Epoch 1/10000\n",
      "0s - loss: 140.6711 - val_loss: 118.6925\n",
      "Epoch 2/10000\n",
      "0s - loss: 119.3671 - val_loss: 104.5505\n",
      "Epoch 3/10000\n",
      "0s - loss: 105.1846 - val_loss: 92.3521\n",
      "Epoch 4/10000\n",
      "0s - loss: 92.9484 - val_loss: 81.2514\n",
      "Epoch 5/10000\n",
      "0s - loss: 81.8104 - val_loss: 71.1430\n",
      "Epoch 6/10000\n",
      "0s - loss: 71.6653 - val_loss: 62.0873\n",
      "Epoch 7/10000\n",
      "0s - loss: 62.5744 - val_loss: 54.1234\n",
      "Epoch 8/10000\n",
      "0s - loss: 54.5771 - val_loss: 47.2122\n",
      "Epoch 9/10000\n",
      "0s - loss: 47.6351 - val_loss: 41.2467\n",
      "Epoch 10/10000\n",
      "0s - loss: 41.6413 - val_loss: 36.0870\n",
      "Epoch 11/10000\n",
      "0s - loss: 36.4555 - val_loss: 31.5944\n",
      "Epoch 12/10000\n",
      "0s - loss: 31.9387 - val_loss: 27.6497\n",
      "Epoch 13/10000\n",
      "0s - loss: 27.9713 - val_loss: 24.1571\n",
      "Epoch 14/10000\n",
      "0s - loss: 24.4574 - val_loss: 21.0436\n",
      "Epoch 15/10000\n",
      "0s - loss: 21.3236 - val_loss: 18.2566\n",
      "Epoch 16/10000\n",
      "0s - loss: 18.5171 - val_loss: 15.7601\n",
      "Epoch 17/10000\n",
      "0s - loss: 16.0018 - val_loss: 13.5285\n",
      "Epoch 18/10000\n",
      "0s - loss: 13.7521 - val_loss: 11.5420\n",
      "Epoch 19/10000\n",
      "0s - loss: 11.7482 - val_loss: 9.7837\n",
      "Epoch 20/10000\n",
      "0s - loss: 9.9732 - val_loss: 8.2367\n",
      "Epoch 21/10000\n",
      "0s - loss: 8.4102 - val_loss: 6.8834\n",
      "Epoch 22/10000\n",
      "0s - loss: 7.0416 - val_loss: 5.7064\n",
      "Epoch 23/10000\n",
      "0s - loss: 5.8499 - val_loss: 4.6892\n",
      "Epoch 24/10000\n",
      "0s - loss: 4.8187 - val_loss: 3.8166\n",
      "Epoch 25/10000\n",
      "0s - loss: 3.9329 - val_loss: 3.0745\n",
      "Epoch 26/10000\n",
      "0s - loss: 3.1781 - val_loss: 2.4493\n",
      "Epoch 27/10000\n",
      "0s - loss: 2.5410 - val_loss: 1.9285\n",
      "Epoch 28/10000\n",
      "0s - loss: 2.0090 - val_loss: 1.5005\n",
      "Epoch 29/10000\n",
      "0s - loss: 1.5704 - val_loss: 1.1542\n",
      "Epoch 30/10000\n",
      "0s - loss: 1.2142 - val_loss: 0.8788\n",
      "Epoch 31/10000\n",
      "0s - loss: 0.9296 - val_loss: 0.6639\n",
      "Epoch 32/10000\n",
      "0s - loss: 0.7062 - val_loss: 0.4999\n",
      "Epoch 33/10000\n",
      "0s - loss: 0.5344 - val_loss: 0.3781\n",
      "Epoch 34/10000\n",
      "0s - loss: 0.4056 - val_loss: 0.2908\n",
      "Epoch 35/10000\n",
      "0s - loss: 0.3117 - val_loss: 0.2309\n",
      "Epoch 36/10000\n",
      "0s - loss: 0.2460 - val_loss: 0.1925\n",
      "Epoch 37/10000\n",
      "0s - loss: 0.2025 - val_loss: 0.1706\n",
      "Epoch 38/10000\n",
      "0s - loss: 0.1759 - val_loss: 0.1606\n",
      "Epoch 39/10000\n",
      "0s - loss: 0.1618 - val_loss: 0.1591\n",
      "Epoch 40/10000\n",
      "0s - loss: 0.1568 - val_loss: 0.1632\n",
      "Epoch 41/10000\n",
      "0s - loss: 0.1578 - val_loss: 0.1706\n",
      "Epoch 42/10000\n",
      "0s - loss: 0.1626 - val_loss: 0.1795\n",
      "Epoch 43/10000\n",
      "0s - loss: 0.1693 - val_loss: 0.1887\n",
      "Epoch 44/10000\n",
      "0s - loss: 0.1767 - val_loss: 0.1972\n",
      "Epoch 45/10000\n",
      "0s - loss: 0.1838 - val_loss: 0.2045\n",
      "Epoch 46/10000\n",
      "0s - loss: 0.1901 - val_loss: 0.2103\n",
      "Epoch 47/10000\n",
      "0s - loss: 0.1951 - val_loss: 0.2145\n",
      "Epoch 48/10000\n",
      "0s - loss: 0.1986 - val_loss: 0.2169\n",
      "Epoch 49/10000\n",
      "0s - loss: 0.2008 - val_loss: 0.2179\n",
      "Epoch 50/10000\n",
      "0s - loss: 0.2016 - val_loss: 0.2175\n",
      "Epoch 51/10000\n",
      "0s - loss: 0.2012 - val_loss: 0.2159\n",
      "Epoch 52/10000\n",
      "0s - loss: 0.1999 - val_loss: 0.2134\n",
      "Epoch 53/10000\n",
      "0s - loss: 0.1977 - val_loss: 0.2102\n",
      "Epoch 54/10000\n",
      "0s - loss: 0.1949 - val_loss: 0.2065\n",
      "Epoch 55/10000\n",
      "0s - loss: 0.1918 - val_loss: 0.2026\n",
      "Epoch 56/10000\n",
      "0s - loss: 0.1884 - val_loss: 0.1985\n",
      "Epoch 57/10000\n",
      "0s - loss: 0.1849 - val_loss: 0.1944\n",
      "Epoch 58/10000\n",
      "0s - loss: 0.1814 - val_loss: 0.1904\n",
      "Epoch 59/10000\n",
      "0s - loss: 0.1781 - val_loss: 0.1866\n",
      "Epoch 60/10000\n",
      "0s - loss: 0.1750 - val_loss: 0.1830\n",
      "Epoch 61/10000\n",
      "0s - loss: 0.1722 - val_loss: 0.1798\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEACAYAAABBOusMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ead241908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.objectives import MSE, MAE\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import theano.tensor as T\n",
    "\n",
    "def custom_loss(y_true,y_pred):  \n",
    "    return T.mean(T.square(y_pred - y_true), axis=-1)\n",
    "    #return T.sum(T.dot(y_true,T.transpose(T.square(T.square(y_pred) - T.square(y_true)))), axis=-1)  \n",
    "    #return loss  \n",
    "\n",
    "\n",
    "in_out_neurons = 318\n",
    "hidden_neurons = 300\n",
    "\n",
    "# model = Sequential()  \n",
    "# model.add(LSTM(input_dim=train.shape[1], output_dim=hidden_neurons, return_sequences=False))  \n",
    "# model.add(Dense(input_dim=hidden_neurons, output_dim=1))  \n",
    "# model.add(Activation(\"linear\"))  \n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")  \n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "#model.add(Dense(input_dim=in_out_neurons, output_dim=hidden_neurons, return_sequences=False))\n",
    "model.add(Dense(input_dim=in_out_neurons, output_dim=128,init=\"uniform\"))  \n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(output_dim=hidden_neurons))  \n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "#model.add(Dropout(0.1))\n",
    "  \n",
    "#model.add(Dense(output_dim=int())\n",
    "# model.add(Activation(\"relu\"))\n",
    "# #model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "# model.add(Dense(output_dim=int(2*(train.shape[1]))))\n",
    "# model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "#model.add(Dense(output_dim=1))\n",
    "\n",
    "\n",
    "# model.compile(\"nadam\", loss=custom_loss)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"nadam\")  \n",
    "    \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "train_log = model.fit(np.array((train)), (np.log(target)),\n",
    "                          batch_size=32,\n",
    "                          nb_epoch=1000, validation_split=0.1,\n",
    "                          verbose=2,\n",
    "                          shuffle=True,\n",
    "                          show_accuracy = True,\n",
    "                          callbacks=[early_stopping]\n",
    "                          )\n",
    "\n",
    "#loss_and_metrics = model.evaluate(np.array(train), np.array(target))\n",
    "#print(loss_and_metrics)\n",
    "\n",
    "plt.plot(train_log.history[\"loss\"], label=\"loss\")\n",
    "#plt.plot(train_log.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "pred_nn = np.exp(model.predict(np.array(test)))\n",
    "#print(Y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: 318\n",
      "Adding Layer 0: 256\n",
      "Adding relu layer\n",
      "Adding 0.33 dropout\n",
      "Adding Layer 1: 128\n",
      "Adding relu layer\n",
      "Adding 0.33 dropout\n",
      "Adding Layer 2: 64\n",
      "Adding relu layer\n",
      "Adding 0.33 dropout\n",
      "Epoch 1/5000\n",
      "1460/1460 [==============================] - 0s - loss: 141.7184     \n",
      "Epoch 2/5000\n",
      "1460/1460 [==============================] - 0s - loss: 121.0507     \n",
      "Epoch 3/5000\n",
      "1460/1460 [==============================] - 0s - loss: 69.3797     \n",
      "Epoch 4/5000\n",
      "1460/1460 [==============================] - 0s - loss: 22.1645     \n",
      "Epoch 5/5000\n",
      "1460/1460 [==============================] - 0s - loss: 6.0962     \n",
      "Epoch 6/5000\n",
      "1460/1460 [==============================] - 0s - loss: 4.3373     \n",
      "Epoch 7/5000\n",
      "1460/1460 [==============================] - 0s - loss: 3.7301     \n",
      "Epoch 8/5000\n",
      "1460/1460 [==============================] - 0s - loss: 3.8520     \n",
      "Epoch 9/5000\n",
      "1460/1460 [==============================] - 0s - loss: 3.5157     \n",
      "Epoch 10/5000\n",
      "1460/1460 [==============================] - 0s - loss: 3.0246     \n",
      "Epoch 11/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.9436     \n",
      "Epoch 12/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.9107     \n",
      "Epoch 13/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.7066     \n",
      "Epoch 14/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.6366     \n",
      "Epoch 15/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.9526     \n",
      "Epoch 16/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.4423     \n",
      "Epoch 17/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.1690     \n",
      "Epoch 18/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.3401     \n",
      "Epoch 19/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.2297     \n",
      "Epoch 20/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.1592     \n",
      "Epoch 21/5000\n",
      "1460/1460 [==============================] - 0s - loss: 2.1886     \n",
      "Epoch 22/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.8091     \n",
      "Epoch 23/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.8723     \n",
      "Epoch 24/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.7817     \n",
      "Epoch 25/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.8687     \n",
      "Epoch 26/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.8076     \n",
      "Epoch 27/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.6251     \n",
      "Epoch 28/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.6485     \n",
      "Epoch 29/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.6310     \n",
      "Epoch 30/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.6570     \n",
      "Epoch 31/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.5306     \n",
      "Epoch 32/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.5911     \n",
      "Epoch 33/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.4199     \n",
      "Epoch 34/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.4417     \n",
      "Epoch 35/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.4569     \n",
      "Epoch 36/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.4281     \n",
      "Epoch 37/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2888     \n",
      "Epoch 38/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2304     \n",
      "Epoch 39/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.3099     \n",
      "Epoch 40/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.3173     \n",
      "Epoch 41/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.3244     \n",
      "Epoch 42/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2056     \n",
      "Epoch 43/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2548     \n",
      "Epoch 44/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2415     \n",
      "Epoch 45/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2533     \n",
      "Epoch 46/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2573     \n",
      "Epoch 47/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2010     \n",
      "Epoch 48/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1691     \n",
      "Epoch 49/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1424     \n",
      "Epoch 50/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0995     \n",
      "Epoch 51/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1482     \n",
      "Epoch 52/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1906     \n",
      "Epoch 53/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1420     \n",
      "Epoch 54/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.2098     \n",
      "Epoch 55/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0684     \n",
      "Epoch 56/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0936     \n",
      "Epoch 57/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1690     \n",
      "Epoch 58/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1025     \n",
      "Epoch 59/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1569     \n",
      "Epoch 60/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.1423     \n",
      "Epoch 61/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0534     \n",
      "Epoch 62/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0221     \n",
      "Epoch 63/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0453     \n",
      "Epoch 64/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0607     \n",
      "Epoch 65/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0784     \n",
      "Epoch 66/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0777     \n",
      "Epoch 67/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0088     \n",
      "Epoch 68/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0758     \n",
      "Epoch 69/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0576     \n",
      "Epoch 70/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0118     \n",
      "Epoch 71/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0586     \n",
      "Epoch 72/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0372     \n",
      "Epoch 73/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0175     \n",
      "Epoch 74/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0404     \n",
      "Epoch 75/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0207     \n",
      "Epoch 76/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9942     \n",
      "Epoch 77/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0148     \n",
      "Epoch 78/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0297     \n",
      "Epoch 79/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9652     \n",
      "Epoch 80/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0648     \n",
      "Epoch 81/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9344     \n",
      "Epoch 82/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9943     \n",
      "Epoch 83/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0150     \n",
      "Epoch 84/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9762     \n",
      "Epoch 85/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9539     \n",
      "Epoch 86/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9763     \n",
      "Epoch 87/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0010     \n",
      "Epoch 88/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9545     \n",
      "Epoch 89/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9832     \n",
      "Epoch 90/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0319     \n",
      "Epoch 91/5000\n",
      "1460/1460 [==============================] - 0s - loss: 1.0655     \n",
      "Epoch 92/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9628     \n",
      "Epoch 93/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9664     \n",
      "Epoch 94/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9382     \n",
      "Epoch 95/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9892     \n",
      "Epoch 96/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9608     \n",
      "Epoch 97/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9803     \n",
      "Epoch 98/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9193     \n",
      "Epoch 99/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9349     \n",
      "Epoch 100/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9529     \n",
      "Epoch 101/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9506     \n",
      "Epoch 102/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9475     \n",
      "Epoch 103/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9477     \n",
      "Epoch 104/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9115     \n",
      "Epoch 105/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9676     \n",
      "Epoch 106/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9517     \n",
      "Epoch 107/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9106     \n",
      "Epoch 108/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9636     \n",
      "Epoch 109/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9617     \n",
      "Epoch 110/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8976     \n",
      "Epoch 111/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8999     \n",
      "Epoch 112/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9466     \n",
      "Epoch 113/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9927     \n",
      "Epoch 114/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8843     \n",
      "Epoch 115/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9426     \n",
      "Epoch 116/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8977     \n",
      "Epoch 117/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8971     \n",
      "Epoch 118/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8592     \n",
      "Epoch 119/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9181     \n",
      "Epoch 120/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8838     \n",
      "Epoch 121/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8667     \n",
      "Epoch 122/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8763     \n",
      "Epoch 123/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8587     \n",
      "Epoch 124/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9071     \n",
      "Epoch 125/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8928     \n",
      "Epoch 126/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9122     \n",
      "Epoch 127/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9047     \n",
      "Epoch 128/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8776     \n",
      "Epoch 129/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8663     \n",
      "Epoch 130/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8779     \n",
      "Epoch 131/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.9481     \n",
      "Epoch 132/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8288     \n",
      "Epoch 133/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8453     \n",
      "Epoch 134/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8787     \n",
      "Epoch 135/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8131     \n",
      "Epoch 136/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8326     \n",
      "Epoch 137/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8442     \n",
      "Epoch 138/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8011     \n",
      "Epoch 139/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7891     \n",
      "Epoch 140/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7899     \n",
      "Epoch 141/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8020     \n",
      "Epoch 142/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7807     \n",
      "Epoch 143/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7958     \n",
      "Epoch 144/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8229     \n",
      "Epoch 145/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7646     \n",
      "Epoch 146/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8201     \n",
      "Epoch 147/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7694     \n",
      "Epoch 148/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8127     \n",
      "Epoch 149/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7866     \n",
      "Epoch 150/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7822     \n",
      "Epoch 151/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8111     \n",
      "Epoch 152/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7690     \n",
      "Epoch 153/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7835     \n",
      "Epoch 154/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.8170     \n",
      "Epoch 155/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7794     \n",
      "Epoch 156/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7482     \n",
      "Epoch 157/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7494     \n",
      "Epoch 158/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7549     \n",
      "Epoch 159/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7100     \n",
      "Epoch 160/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7539     \n",
      "Epoch 161/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7745     \n",
      "Epoch 162/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7100     \n",
      "Epoch 163/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6545     \n",
      "Epoch 164/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7409     \n",
      "Epoch 165/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7231     \n",
      "Epoch 166/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6962     \n",
      "Epoch 167/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7286     \n",
      "Epoch 168/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7332     \n",
      "Epoch 169/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6386     \n",
      "Epoch 170/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7546     \n",
      "Epoch 171/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6708     \n",
      "Epoch 172/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6637     \n",
      "Epoch 173/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6949     \n",
      "Epoch 174/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6434     \n",
      "Epoch 175/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6925     \n",
      "Epoch 176/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6415     \n",
      "Epoch 177/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6606     \n",
      "Epoch 178/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.7052     \n",
      "Epoch 179/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6368     \n",
      "Epoch 180/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6537     \n",
      "Epoch 181/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6474     \n",
      "Epoch 182/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6116     \n",
      "Epoch 183/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6291     \n",
      "Epoch 184/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6345     \n",
      "Epoch 185/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6205     \n",
      "Epoch 186/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6406     \n",
      "Epoch 187/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6237     \n",
      "Epoch 188/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6690     \n",
      "Epoch 189/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5710     \n",
      "Epoch 190/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5794     \n",
      "Epoch 191/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5754     \n",
      "Epoch 192/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6054     \n",
      "Epoch 193/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.6083     \n",
      "Epoch 194/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5988     \n",
      "Epoch 195/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5870     \n",
      "Epoch 196/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5966     \n",
      "Epoch 197/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5826     \n",
      "Epoch 198/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5300     \n",
      "Epoch 199/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5762     \n",
      "Epoch 200/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5806     \n",
      "Epoch 201/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5337     \n",
      "Epoch 202/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5542     \n",
      "Epoch 203/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5136     \n",
      "Epoch 204/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5397     \n",
      "Epoch 205/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5513     \n",
      "Epoch 206/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5430     \n",
      "Epoch 207/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5571     \n",
      "Epoch 208/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5503     \n",
      "Epoch 209/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5391     \n",
      "Epoch 210/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5436     \n",
      "Epoch 211/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5318     \n",
      "Epoch 212/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5113     \n",
      "Epoch 213/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5144     \n",
      "Epoch 214/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5125     \n",
      "Epoch 215/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5199     \n",
      "Epoch 216/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5104     \n",
      "Epoch 217/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5020     \n",
      "Epoch 218/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4536     \n",
      "Epoch 219/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4806     \n",
      "Epoch 220/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4869     \n",
      "Epoch 221/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4816     \n",
      "Epoch 222/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5048     \n",
      "Epoch 223/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.5037     \n",
      "Epoch 224/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4916     \n",
      "Epoch 225/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4744     \n",
      "Epoch 226/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4781     \n",
      "Epoch 227/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4552     \n",
      "Epoch 228/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4401     \n",
      "Epoch 229/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4589     \n",
      "Epoch 230/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4756     \n",
      "Epoch 231/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4612     \n",
      "Epoch 232/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4291     \n",
      "Epoch 233/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4531     \n",
      "Epoch 234/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4198     \n",
      "Epoch 235/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4503     \n",
      "Epoch 236/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4455     \n",
      "Epoch 237/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4081     \n",
      "Epoch 238/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4105     \n",
      "Epoch 239/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4316     \n",
      "Epoch 240/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4041     \n",
      "Epoch 241/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4274     \n",
      "Epoch 242/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4040     \n",
      "Epoch 243/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4050     \n",
      "Epoch 244/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4229     \n",
      "Epoch 245/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4189     \n",
      "Epoch 246/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4068     \n",
      "Epoch 247/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3761     \n",
      "Epoch 248/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4005     \n",
      "Epoch 249/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3759     \n",
      "Epoch 250/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3704     \n",
      "Epoch 251/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.4057     \n",
      "Epoch 252/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3772     \n",
      "Epoch 253/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3858     \n",
      "Epoch 254/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3709     \n",
      "Epoch 255/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3575     \n",
      "Epoch 256/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3850     \n",
      "Epoch 257/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3790     \n",
      "Epoch 258/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3670     \n",
      "Epoch 259/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3325     \n",
      "Epoch 260/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3536     \n",
      "Epoch 261/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3660     \n",
      "Epoch 262/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3465     \n",
      "Epoch 263/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3049     \n",
      "Epoch 264/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3161     \n",
      "Epoch 265/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3306     \n",
      "Epoch 266/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3406     \n",
      "Epoch 267/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3405     \n",
      "Epoch 268/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3245     \n",
      "Epoch 269/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3210     \n",
      "Epoch 270/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3225     \n",
      "Epoch 271/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3308     \n",
      "Epoch 272/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3218     \n",
      "Epoch 273/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3295     \n",
      "Epoch 274/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3201     \n",
      "Epoch 275/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3156     \n",
      "Epoch 276/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3114     \n",
      "Epoch 277/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3250     \n",
      "Epoch 278/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.3009     \n",
      "Epoch 279/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2996     \n",
      "Epoch 280/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2990     \n",
      "Epoch 281/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2999     \n",
      "Epoch 282/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2954     \n",
      "Epoch 283/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2875     \n",
      "Epoch 284/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2829     \n",
      "Epoch 285/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2697     \n",
      "Epoch 286/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2600     \n",
      "Epoch 287/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2814     \n",
      "Epoch 288/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2737     \n",
      "Epoch 289/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2654     \n",
      "Epoch 290/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2786     \n",
      "Epoch 291/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2747     \n",
      "Epoch 292/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2613     \n",
      "Epoch 293/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2786     \n",
      "Epoch 294/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2615     \n",
      "Epoch 295/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2410     \n",
      "Epoch 296/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2613     \n",
      "Epoch 297/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2508     \n",
      "Epoch 298/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2636     \n",
      "Epoch 299/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2556     \n",
      "Epoch 300/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2536     \n",
      "Epoch 301/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2465     \n",
      "Epoch 302/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2509     \n",
      "Epoch 303/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2358     \n",
      "Epoch 304/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2324     \n",
      "Epoch 305/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2386     \n",
      "Epoch 306/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2294     \n",
      "Epoch 307/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2299     \n",
      "Epoch 308/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2292     \n",
      "Epoch 309/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2190     \n",
      "Epoch 310/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2320     \n",
      "Epoch 311/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2292     \n",
      "Epoch 312/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2266     \n",
      "Epoch 313/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2184     \n",
      "Epoch 314/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2157     \n",
      "Epoch 315/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2187     \n",
      "Epoch 316/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2122     \n",
      "Epoch 317/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2198     \n",
      "Epoch 318/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2076     \n",
      "Epoch 319/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2080     \n",
      "Epoch 320/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2189     \n",
      "Epoch 321/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2007     \n",
      "Epoch 322/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2065     \n",
      "Epoch 323/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2041     \n",
      "Epoch 324/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1961     \n",
      "Epoch 325/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1880     \n",
      "Epoch 326/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1901     \n",
      "Epoch 327/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1967     \n",
      "Epoch 328/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.2049     \n",
      "Epoch 329/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1923     \n",
      "Epoch 330/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1916     \n",
      "Epoch 331/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1745     \n",
      "Epoch 332/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1899     \n",
      "Epoch 333/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1884     \n",
      "Epoch 334/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1669     \n",
      "Epoch 335/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1738     \n",
      "Epoch 336/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1689     \n",
      "Epoch 337/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1653     \n",
      "Epoch 338/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1674     \n",
      "Epoch 339/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1701     \n",
      "Epoch 340/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1598     \n",
      "Epoch 341/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1760     \n",
      "Epoch 342/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1619     \n",
      "Epoch 343/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1651     \n",
      "Epoch 344/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1660     \n",
      "Epoch 345/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1655     \n",
      "Epoch 346/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1645     \n",
      "Epoch 347/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1612     \n",
      "Epoch 348/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1671     \n",
      "Epoch 349/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1506     \n",
      "Epoch 350/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1589     \n",
      "Epoch 351/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1557     \n",
      "Epoch 352/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1561     \n",
      "Epoch 353/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1494     \n",
      "Epoch 354/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1382     \n",
      "Epoch 355/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1460     \n",
      "Epoch 356/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1366     \n",
      "Epoch 357/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1425     \n",
      "Epoch 358/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1386     \n",
      "Epoch 359/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1454     \n",
      "Epoch 360/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1402     \n",
      "Epoch 361/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1447     \n",
      "Epoch 362/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1303     \n",
      "Epoch 363/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1358     \n",
      "Epoch 364/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1307     \n",
      "Epoch 365/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1368     \n",
      "Epoch 366/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1270     \n",
      "Epoch 367/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1394     \n",
      "Epoch 368/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1220     \n",
      "Epoch 369/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1246     \n",
      "Epoch 370/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1184     \n",
      "Epoch 371/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1259     \n",
      "Epoch 372/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1288     \n",
      "Epoch 373/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1193     \n",
      "Epoch 374/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1220     \n",
      "Epoch 375/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1189     \n",
      "Epoch 376/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1177     \n",
      "Epoch 377/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1196     \n",
      "Epoch 378/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1173     \n",
      "Epoch 379/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1059     \n",
      "Epoch 380/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1098     \n",
      "Epoch 381/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1100     \n",
      "Epoch 382/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1076     \n",
      "Epoch 383/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 384/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1118     \n",
      "Epoch 385/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1150     \n",
      "Epoch 386/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1143     \n",
      "Epoch 387/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1132     \n",
      "Epoch 388/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0999     \n",
      "Epoch 389/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1025     \n",
      "Epoch 390/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1008     \n",
      "Epoch 391/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.1023     \n",
      "Epoch 392/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0998     \n",
      "Epoch 393/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0969     \n",
      "Epoch 394/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0953     \n",
      "Epoch 395/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0917     \n",
      "Epoch 396/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0916     \n",
      "Epoch 397/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0928     \n",
      "Epoch 398/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0976     \n",
      "Epoch 399/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0902     \n",
      "Epoch 400/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0859     \n",
      "Epoch 401/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0916     \n",
      "Epoch 402/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0860     \n",
      "Epoch 403/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0888     \n",
      "Epoch 404/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0826     \n",
      "Epoch 405/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0853     \n",
      "Epoch 406/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0753     \n",
      "Epoch 407/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0838     \n",
      "Epoch 408/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0867     \n",
      "Epoch 409/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0856     \n",
      "Epoch 410/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0860     \n",
      "Epoch 411/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0848     \n",
      "Epoch 412/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0803     \n",
      "Epoch 413/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0820     \n",
      "Epoch 414/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 415/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0731     \n",
      "Epoch 416/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0763     \n",
      "Epoch 417/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0712     \n",
      "Epoch 418/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0729     \n",
      "Epoch 419/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0776     \n",
      "Epoch 420/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0742     \n",
      "Epoch 421/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0684     \n",
      "Epoch 422/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0773     \n",
      "Epoch 423/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0717     \n",
      "Epoch 424/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0715     \n",
      "Epoch 425/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0668     \n",
      "Epoch 426/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0753     \n",
      "Epoch 427/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0672     \n",
      "Epoch 428/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0660     \n",
      "Epoch 429/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0717     \n",
      "Epoch 430/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0662     \n",
      "Epoch 431/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0635     \n",
      "Epoch 432/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0628     \n",
      "Epoch 433/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0597     \n",
      "Epoch 434/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0641     \n",
      "Epoch 435/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0600     \n",
      "Epoch 436/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0660     \n",
      "Epoch 437/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0646     \n",
      "Epoch 438/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0600     \n",
      "Epoch 439/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0608     \n",
      "Epoch 440/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0603     \n",
      "Epoch 441/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0629     \n",
      "Epoch 442/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0598     \n",
      "Epoch 443/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0596     \n",
      "Epoch 444/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0546     \n",
      "Epoch 445/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0600     \n",
      "Epoch 446/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0568     \n",
      "Epoch 447/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0594     \n",
      "Epoch 448/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0573     \n",
      "Epoch 449/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0532     \n",
      "Epoch 450/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0556     \n",
      "Epoch 451/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0539     \n",
      "Epoch 452/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0483     \n",
      "Epoch 453/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0514     \n",
      "Epoch 454/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0484     \n",
      "Epoch 455/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0510     \n",
      "Epoch 456/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0515     \n",
      "Epoch 457/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0509     \n",
      "Epoch 458/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0452     \n",
      "Epoch 459/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0484     \n",
      "Epoch 460/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0459     \n",
      "Epoch 461/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0482     \n",
      "Epoch 462/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0496     \n",
      "Epoch 463/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0452     \n",
      "Epoch 464/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0461     \n",
      "Epoch 465/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0484     \n",
      "Epoch 466/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0452     \n",
      "Epoch 467/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0510     \n",
      "Epoch 468/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0440     \n",
      "Epoch 469/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0421     \n",
      "Epoch 470/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0487     \n",
      "Epoch 471/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0375     \n",
      "Epoch 472/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0443     \n",
      "Epoch 473/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0402     \n",
      "Epoch 474/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0409     \n",
      "Epoch 475/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0419     \n",
      "Epoch 476/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0435     \n",
      "Epoch 477/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0440     \n",
      "Epoch 478/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0377     \n",
      "Epoch 479/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0417     \n",
      "Epoch 480/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0422     \n",
      "Epoch 481/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0421     \n",
      "Epoch 482/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0379     \n",
      "Epoch 483/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0417     \n",
      "Epoch 484/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0374     \n",
      "Epoch 485/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0430     \n",
      "Epoch 486/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0388     \n",
      "Epoch 487/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0374     \n",
      "Epoch 488/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0374     \n",
      "Epoch 489/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0364     \n",
      "Epoch 490/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0360     \n",
      "Epoch 491/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0356     \n",
      "Epoch 492/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0355     \n",
      "Epoch 493/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0351     \n",
      "Epoch 494/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0383     \n",
      "Epoch 495/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0364     \n",
      "Epoch 496/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0355     \n",
      "Epoch 497/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0379     \n",
      "Epoch 498/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0352     \n",
      "Epoch 499/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0359     \n",
      "Epoch 500/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0313     \n",
      "Epoch 501/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0378     \n",
      "Epoch 502/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0328     \n",
      "Epoch 503/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0372     \n",
      "Epoch 504/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0347     \n",
      "Epoch 505/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0345     \n",
      "Epoch 506/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0327     \n",
      "Epoch 507/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0318     \n",
      "Epoch 508/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0321     \n",
      "Epoch 509/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0345     \n",
      "Epoch 510/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0309     \n",
      "Epoch 511/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0328     \n",
      "Epoch 512/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0306     \n",
      "Epoch 513/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0314     \n",
      "Epoch 514/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0306     \n",
      "Epoch 515/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0309     \n",
      "Epoch 516/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0286     \n",
      "Epoch 517/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0305     \n",
      "Epoch 518/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0325     \n",
      "Epoch 519/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0298     \n",
      "Epoch 520/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0301     \n",
      "Epoch 521/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0305     \n",
      "Epoch 522/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0299     \n",
      "Epoch 523/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0284     \n",
      "Epoch 524/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0278     \n",
      "Epoch 525/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0275     \n",
      "Epoch 526/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0299     \n",
      "Epoch 527/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0271     \n",
      "Epoch 528/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0294     \n",
      "Epoch 529/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0291     \n",
      "Epoch 530/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0259     \n",
      "Epoch 531/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0268     \n",
      "Epoch 532/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0260     \n",
      "Epoch 533/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0283     \n",
      "Epoch 534/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0280     \n",
      "Epoch 535/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0255     \n",
      "Epoch 536/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0265     \n",
      "Epoch 537/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0271     \n",
      "Epoch 538/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0261     \n",
      "Epoch 539/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0251     \n",
      "Epoch 540/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0293     \n",
      "Epoch 541/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0268     \n",
      "Epoch 542/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0257     \n",
      "Epoch 543/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0274     \n",
      "Epoch 544/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0254     \n",
      "Epoch 545/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0281     \n",
      "Epoch 546/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0238     \n",
      "Epoch 547/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0268     \n",
      "Epoch 548/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0265     \n",
      "Epoch 549/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0246     \n",
      "Epoch 550/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0246     \n",
      "Epoch 551/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0270     \n",
      "Epoch 552/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0235     \n",
      "Epoch 553/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0229     \n",
      "Epoch 554/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0257     \n",
      "Epoch 555/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0235     \n",
      "Epoch 556/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0225     \n",
      "Epoch 557/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0264     \n",
      "Epoch 558/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0231     \n",
      "Epoch 559/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0230     \n",
      "Epoch 560/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0241     \n",
      "Epoch 561/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0241     \n",
      "Epoch 562/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0235     \n",
      "Epoch 563/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0211     \n",
      "Epoch 564/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0216     \n",
      "Epoch 565/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0233     \n",
      "Epoch 566/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0282     \n",
      "Epoch 567/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0242     \n",
      "Epoch 568/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0239     \n",
      "Epoch 569/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0216     \n",
      "Epoch 570/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0247     \n",
      "Epoch 571/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0247     \n",
      "Epoch 572/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0229     \n",
      "Epoch 573/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0221     \n",
      "Epoch 574/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0252     \n",
      "Epoch 575/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0211     \n",
      "Epoch 576/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0237     \n",
      "Epoch 577/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0245     \n",
      "Epoch 578/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0232     \n",
      "Epoch 579/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0223     \n",
      "Epoch 580/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0205     \n",
      "Epoch 581/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0206     \n",
      "Epoch 582/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0203     \n",
      "Epoch 583/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0211     \n",
      "Epoch 584/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0202     \n",
      "Epoch 585/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0197     \n",
      "Epoch 586/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0223     \n",
      "Epoch 587/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0208     \n",
      "Epoch 588/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0199     \n",
      "Epoch 589/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0195     \n",
      "Epoch 590/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0197     \n",
      "Epoch 591/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0198     \n",
      "Epoch 592/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0214     \n",
      "Epoch 593/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0187     \n",
      "Epoch 594/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0209     \n",
      "Epoch 595/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0232     \n",
      "Epoch 596/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0206     \n",
      "Epoch 597/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0208     \n",
      "Epoch 598/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0218     \n",
      "Epoch 599/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0232     \n",
      "Epoch 600/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0208     \n",
      "Epoch 601/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0205     \n",
      "Epoch 602/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0179     \n",
      "Epoch 603/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0201     \n",
      "Epoch 604/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 605/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0193     \n",
      "Epoch 606/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0198     \n",
      "Epoch 607/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0200     \n",
      "Epoch 608/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0188     \n",
      "Epoch 609/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0171     \n",
      "Epoch 610/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0174     \n",
      "Epoch 611/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0189     \n",
      "Epoch 612/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0210     \n",
      "Epoch 613/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0184     \n",
      "Epoch 614/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0159     \n",
      "Epoch 615/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0192     \n",
      "Epoch 616/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0190     \n",
      "Epoch 617/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0184     \n",
      "Epoch 618/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0207     \n",
      "Epoch 619/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0187     \n",
      "Epoch 620/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0206     \n",
      "Epoch 621/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0166     \n",
      "Epoch 622/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0182     \n",
      "Epoch 623/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0187     \n",
      "Epoch 624/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0206     \n",
      "Epoch 625/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0191     \n",
      "Epoch 626/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0206     \n",
      "Epoch 627/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0204     \n",
      "Epoch 628/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0204     \n",
      "Epoch 629/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0180     \n",
      "Epoch 630/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0222     \n",
      "Epoch 631/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0169     \n",
      "Epoch 632/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0168     \n",
      "Epoch 633/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0167     \n",
      "Epoch 634/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0175     \n",
      "Epoch 635/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 636/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0180     \n",
      "Epoch 637/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0184     \n",
      "Epoch 638/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0177     \n",
      "Epoch 639/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 640/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0198     \n",
      "Epoch 641/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0182     \n",
      "Epoch 642/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0183     \n",
      "Epoch 643/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0187     \n",
      "Epoch 644/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0202     \n",
      "Epoch 645/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0172     \n",
      "Epoch 646/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0180     \n",
      "Epoch 647/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0163     \n",
      "Epoch 648/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0145     \n",
      "Epoch 649/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0168     \n",
      "Epoch 650/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0171     \n",
      "Epoch 651/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0159     \n",
      "Epoch 652/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0168     \n",
      "Epoch 653/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0200     \n",
      "Epoch 654/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0188     \n",
      "Epoch 655/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0167     \n",
      "Epoch 656/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 657/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0172     \n",
      "Epoch 658/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0171     \n",
      "Epoch 659/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0171     \n",
      "Epoch 660/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0191     \n",
      "Epoch 661/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0166     \n",
      "Epoch 662/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0196     \n",
      "Epoch 663/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0197     \n",
      "Epoch 664/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0184     \n",
      "Epoch 665/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0139     \n",
      "Epoch 666/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0177     \n",
      "Epoch 667/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0197     \n",
      "Epoch 668/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0185     \n",
      "Epoch 669/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0157     \n",
      "Epoch 670/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0196     \n",
      "Epoch 671/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0180     \n",
      "Epoch 672/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0167     \n",
      "Epoch 673/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0165     \n",
      "Epoch 674/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0184     \n",
      "Epoch 675/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0162     \n",
      "Epoch 676/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0165     \n",
      "Epoch 677/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 678/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0164     \n",
      "Epoch 679/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0158     \n",
      "Epoch 680/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0194     \n",
      "Epoch 681/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0192     \n",
      "Epoch 682/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0165     \n",
      "Epoch 683/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0157     \n",
      "Epoch 684/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0168     \n",
      "Epoch 685/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0158     \n",
      "Epoch 686/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0160     \n",
      "Epoch 687/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0147     \n",
      "Epoch 688/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0153     \n",
      "Epoch 689/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0170     \n",
      "Epoch 690/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0162     \n",
      "Epoch 691/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0177     \n",
      "Epoch 692/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0177     \n",
      "Epoch 693/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0151     \n",
      "Epoch 694/5000\n",
      "1460/1460 [==============================] - 0s - loss: 0.0145     \n",
      "Epoch 695/5000\n",
      " 960/1460 [==================>...........] - ETA: 0s - loss: 0.0138"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "class NN:\n",
    "    #Wrapper for Keras NN\n",
    "    #See http://keras.io/ for parameter options\n",
    "    def __init__(self, inputShape, layers, dropout = [],\n",
    "                 activation = 'relu', init = 'uniform', loss = 'rmse',\n",
    "                 optimizer = 'adadelta', nb_epochs = 50, batch_size = 32, verbose = 1,\n",
    "                 patience=10):\n",
    "\n",
    "        model = Sequential()\n",
    "        for i in range(len(layers)):\n",
    "            if i == 0:\n",
    "                print (\"Input shape: \" + str(inputShape))\n",
    "                print (\"Adding Layer \" + str(i) + \": \" + str(layers[i]))\n",
    "                model.add(Dense(layers[i], input_dim = inputShape, init = init))\n",
    "            else:\n",
    "                print (\"Adding Layer \" + str(i) + \": \" + str(layers[i]))\n",
    "                model.add(Dense(layers[i], init = init))\n",
    "            print (\"Adding \" + activation + \" layer\")\n",
    "            model.add(Activation(activation))\n",
    "            model.add(BatchNormalization())\n",
    "            if len(dropout) > i:\n",
    "                print (\"Adding \" + str(dropout[i]) + \" dropout\")\n",
    "                model.add(Dropout(dropout[i]))\n",
    "        model.add(Dense(1, init = init)) #End in a single output node for regression style output\n",
    "        model.compile(loss=loss, optimizer=optimizer)\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.model = model\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=self.patience)\n",
    "\n",
    "        self.model.fit(X,y,\n",
    "                       nb_epoch=self.nb_epochs, batch_size=self.batch_size, verbose = self.verbose,\n",
    "                       callbacks=[early_stopping]\n",
    "                      )\n",
    "        \n",
    "    def predict(self, X, batch_size = 128, verbose = 1):\n",
    "        return self.model.predict(X, batch_size = batch_size, verbose = verbose)\n",
    "\n",
    "model = NN(inputShape = train.shape[1],\n",
    "         layers = [256,128,64],\n",
    "         dropout = [0.33,0.33,0.33],\n",
    "         loss=\"mean_squared_error\",\n",
    "         optimizer = 'nadam',\n",
    "         init = 'uniform',\n",
    "         batch_size = 32,\n",
    "         nb_epochs = 5000,\n",
    "          patience=100)\n",
    "\n",
    "\n",
    "train_log = model.fit(np.array((train)), (np.log(target)),\n",
    "                          \n",
    "                          #verbose=2,\n",
    "                          #shuffle=True,\n",
    "                          #show_accuracy = True,\n",
    "                          #callbacks=[early_stopping]\n",
    "                          )\n",
    "\n",
    "pred_nn = np.exp(model.predict(np.array(test)))\n",
    "\n",
    "#plt.plot(train_log.history[\"loss\"], label=\"loss\")\n",
    "#plt.plot(train_log.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "#print(Y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = ((preds+preds2+pred_nn.T)/3.0)[0]\n",
    "# print(y_pred)\n",
    "# Output to CSV\n",
    "pred_df = pd.DataFrame(y_pred, index=test.index.values, columns=[\"SalePrice\"])\n",
    "pred_df.to_csv('submit.txt', header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61940.504302661626"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds-preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2019508.150390625"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((preds - pred_nn.T)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 134089.53125  ,  149049.109375 ,  186540.75     , ...,\n",
       "         182405.234375 ,  121760.2578125,  198176.390625 ]], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pred_nn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
